{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bivariate_plots.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dr1hzhNOIR8B"
      },
      "source": [
        "This notebook will help reproduce figure (4) in the paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iJaGgOyGIMZK",
        "pycharm": {
          "is_executing": true
        },
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "frS3_2GgKQBH"
      },
      "source": [
        "Here, we collect data by looking at a pair of files (an input (code) and output (comments) file). We take 2 random lines, and plot the bleu scores of the inputs (code lines) and outputs (comment lines)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qK-YerUwIv7E",
        "pycharm": {
          "is_executing": true
        },
        "colab": {}
      },
      "source": [
        "def collect_data(args):\n",
        "\tnum_samples = 10000 if args[\"num_samples\"] is None else int(args[\"num_samples\"])\n",
        "\tno_zeroes = args[\"no_zeroes\"]\n",
        "\n",
        "\toutput_csv_file = open(args[\"csv_file\"], \"w\")\n",
        "\toutput_csv_file.write(\"input_bleu,output_bleu\\n\")\n",
        "\n",
        "\tfile_inputs = open(args[\"input_file\"], \"r\")\n",
        "\tfile_outputs = open(args[\"output_file\"], \"r\")\n",
        "\n",
        "\tall_inputs = []\n",
        "\tall_outputs = []\n",
        "\n",
        "\tsmoothing = SmoothingFunction()\n",
        "\n",
        "\t\"\"\"\n",
        "\tHere, we take each pair of input-output lines, split them by space, and append them to lists\n",
        "\tall_inputs and all_outputs. For funcom, we make sure to remove the <s> and </s> tokens from the\n",
        "\toutputs (comments) to prevent artificially increasing BLEU scores.\n",
        "\t\"\"\"\n",
        "\tfor (input, output) in zip(file_inputs.readlines(), file_outputs.readlines()):\n",
        "\t\tinput_splitted, input_len = input.split(\" \"), len(input.split(\" \"))\n",
        "\t\toutput_splitted, output_len = output.split(\" \"), len(output.split(\" \"))\n",
        "\t\tall_inputs.append(input_splitted)\n",
        "\t\tall_outputs.append(output_splitted)\n",
        "\n",
        "\t\"\"\"\n",
        "\tHere, we iterate through the number of desired samples (10k in our setting). We randomly select\n",
        "\t2 input-output pairs without replacement to prevent (although unlikely) the possibility of\n",
        "\tpicking the exact same pairs. We calculate the BLEU using BLEU-4 with the appropriate smoothing\n",
        "\tfunction.\n",
        "\t\"\"\"\n",
        "\tfor iter in tqdm(range(num_samples)):\n",
        "\t\tidxes = np.random.choice(len(all_inputs), 2, replace=False)\n",
        "\n",
        "\t\tinput_bleu = sentence_bleu([all_inputs[idxes[0]]], all_inputs[idxes[1]], \n",
        "\t\t\t\t\t\t\t\t\tweights=(0.25,0.25,0.25,0.25), \n",
        "\t\t\t\t\t\t\t\t\tsmoothing_function=smoothing.method2)\n",
        "\t\toutput_bleu = sentence_bleu([all_outputs[idxes[0]]], all_outputs[idxes[1]], \n",
        "\t\t\t\t\t\t\t\t\tweights=(0.25,0.25,0.25,0.25), \n",
        "\t\t\t\t\t\t\t\t\tsmoothing_function=smoothing.method2)\n",
        "\t\tif no_zeroes:\n",
        "\t\t\t\"\"\"\n",
        "\t\t\tcontinue if we want to eliminate very small (essentially zero) values\n",
        "\t\t\t\"\"\"\n",
        "\t\t\tif input_bleu < 1e-5 or output_bleu < 1e-5:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\n",
        "\t\toutput_csv_file.write(f\"{input_bleu},{output_bleu}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rV2kU0vdI_73",
        "pycharm": {
          "is_executing": true
        },
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    \"input_file\": \"plot-data/bivariate/NL/code.txt\",\n",
        "    \"output_file\": \"plot-data/bivariate/NL/comments.txt\",\n",
        "    \"csv_file\": \"nl.csv\",\n",
        "    \"num_samples\": 10000,\n",
        "    \"no_zeroes\": True\n",
        "}\n",
        "collect_data(args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZBTgwZKqyLAd"
      },
      "source": [
        "Now that we've collected the data, we need to run the following commands in R (not done in this notebook), so fire up R studio and input these commands."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VhrB45Ogyk5G"
      },
      "source": [
        "**First install ggplot2 and hexbin for visualization.**\n",
        "\n",
        "install.packages(\"ggplot2\")\n",
        "library(\"ggplot2\")\n",
        "\n",
        "install.packages(\"hexbin\")\n",
        "library(\"hexbin\")\n",
        "\n",
        "**Read the BLEU data and plot.**\n",
        "\n",
        "data = read.csv(/Path/to/bivariate/data)\n",
        "\n",
        "d <- ggplot(data, aes(input_bleu, output_bleu))\n",
        "\n",
        "d + geom_hex(bins = 50) # number of bins can be varied for visualization purposes\n",
        "\n",
        "**If you want to plot multiple plots simulataneously (as seen in figure 4 in the paper)**:\n",
        "\n",
        "First go here: https://cran.r-project.org/web/packages/egg/vignettes/Ecosystem.html\n",
        "Copy the function grid_arrange_shared_legend into R Studio. The run the following additional commands:\n",
        "\n",
        "**Install some more packages**\n",
        "\n",
        "install.packages(\"gridExtra\")\n",
        "library(gridExtra)\n",
        "\n",
        "install.packages(\"ggplotGrob\")\n",
        "library(ggplotGrob)\n",
        "\n",
        "**Read .csv files for each dataset**\n",
        "\n",
        "data_1 = read.csv(/Path/to/bivariate/data_1)\n",
        "\n",
        "... (for all data files you want to plot)\n",
        "\n",
        "data_n = read.csv(/Path/to/bivariate/data_n)\n",
        "\n",
        "**Create the data holder**\n",
        "\n",
        "Some tips: You can change the ends of the limits and the bins for visualization purposes.\n",
        "\n",
        "d_1 = <- ggplot(data_1, aes(input_bleu, output_bleu)) + geom_hex(bins = 50) + ggtitle(title) + scale_x_continuous(limits=c(-1, 30)) + scale_y_continuous(limits=c(-1, 30))\n",
        "... (for all data files you want to plot)\n",
        "\n",
        "d_n = <- ggplot(data_n, aes(input_bleu, output_bleu)) + geom_hex(bins = 50) + ggtitle(title) + scale_x_continuous(limits=c(-1, 30)) + scale_y_continuous(limits=c(-1, 30))\n",
        "\n",
        "**Plot all data in a side-by-side plot**\n",
        "\n",
        "grid_arrange_shared_legend(d_1, ... ,d_n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOWyjX8LzyRh",
        "colab_type": "text"
      },
      "source": [
        "To calculate the Spearman coefficients and the associated p-values, run this function with the correct path to the .csv file created above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hc--oi_5z6mH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "def calculate_spearman(path_to_csv: str) -> None:\n",
        "\tdf = pd.read_csv(path_to_csv)\n",
        "\tinput_bleu = df[\"input_bleu\"].tolist()\n",
        "\toutput_bleu = df[\"output_bleu\"].tolist()\n",
        "\tspearman = spearmanr(input_bleu, output_bleu)\n",
        "\tprint(spearman)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckG-nP6Z0CA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}