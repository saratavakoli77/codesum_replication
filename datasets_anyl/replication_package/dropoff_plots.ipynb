{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dropoff_plots.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dMbh3B2iFqaB"
      },
      "source": [
        "This file helps reproduce figure (3) in the paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Edajb0tf8ohY",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "import random\n",
        "import string\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "\n",
        "from typing import Callable, List"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hYxcA3bu97Hq",
        "colab": {}
      },
      "source": [
        "smoothing = SmoothingFunction() # use NLTK's smoothing functionality"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2F7M3r63-BOE",
        "colab": {}
      },
      "source": [
        "def create_random_token(): # a random pad token to insert into locations of various ngrams\n",
        "    N = 7\n",
        "    res = ''.join(random.choices(string.ascii_uppercase +\n",
        "                             string.digits, k = N)) \n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Fsv4-sn-Teu"
      },
      "source": [
        "This function returns a list of tuples of (ngram, frequency_of_ngram) for the ngram_size specified. We replace these common ngrams with random pad tokens and calculate BLEUs for the dropoff plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyFoZHTokmjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_ngram_list(corpus_file_path: str, ngram_size: int):\n",
        "  ngram_dict_code = {}\n",
        "  with open(corpus_file_path) as f_1:\n",
        "    line = f_1.readline()\n",
        "    code_ngram_count = 0\n",
        "    while line:\n",
        "        line = line.split(\" \")\n",
        "        n_prev_tokens = []\n",
        "        for token in line:\n",
        "            if token == \"\\n\":\n",
        "                break\n",
        "\n",
        "            n_prev_tokens.append(token)\n",
        "            if len(n_prev_tokens) < ngram_size:\n",
        "                continue\n",
        "\n",
        "            code_ngram_count+=1\n",
        "            ngram = \"-\".join(n_prev_tokens)\n",
        "            \n",
        "            if ngram not in ngram_dict_code:\n",
        "                ngram_dict_code[ngram] = 1\n",
        "            else:\n",
        "                ngram_dict_code[ngram]+=1\n",
        "            del n_prev_tokens[0]\n",
        "        line = f_1.readline()\n",
        "  \n",
        "  sorted_list_code = sorted(ngram_dict_code.items(), key=lambda item: item[1], reverse=True)\n",
        "  return sorted_list_code\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mw9YkCCp-_UT"
      },
      "source": [
        "The following function takes as input a line of text, a list of tokens (ngrams to remove), and an ngram_size. The function return an updated line with the removable tokens removed and replaced with a random pad token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFXQgpIGwDth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_ngrams_from_line(input_line: str, list_of_removable_ngrams: List[str], ngram_size: int) -> str:\n",
        "    input_line_split = input_line.split(\" \")\n",
        "    new_input_line = []\n",
        "    n_prev_tokens = [] # list of n previous tokens\n",
        "\n",
        "    for token in input_line_split:\n",
        "\n",
        "        n_prev_tokens.append(token)\n",
        "        new_input_line.append(token)\n",
        "\n",
        "        if len(n_prev_tokens) < ngram_size:\n",
        "          continue\n",
        "        else:\n",
        "          cur_ngram = \"-\".join(n_prev_tokens)\n",
        "\n",
        "        if cur_ngram in list_of_removable_ngrams:\n",
        "            for i in range(1, ngram_size+1): # the current token has already been appended\n",
        "              new_input_line[-i] = create_random_token()\n",
        "\n",
        "        del n_prev_tokens[0]\n",
        "\n",
        "    return new_input_line"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5V_jUJqWEWuH"
      },
      "source": [
        "The function `compute_and_plot` has five parameters:\n",
        "\n",
        "*   `file_path` -> the location of the .txt file\n",
        "*   `ngram_size` -> an integer representing the size of the ngram. e.g. ngram_size = 3 represents a trigram\n",
        "*   `pickle_file_path` -> the location to store the plotting data in a pickle file\n",
        "*   `num_iters` -> number of tokens (ngrams) to remove\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mILf3QqxA-pt",
        "colab": {}
      },
      "source": [
        "def compute_and_plot(file_path: str, ngram_size: int, pickle_file_path: str, num_iters: int=100):\n",
        "    indices = [i for i in range(num_iters)]\n",
        "    sorted_list = get_ngram_list(file_path, ngram_size)\n",
        "    output_list = []\n",
        "\n",
        "    for i in tqdm(range(num_iters)):\n",
        "        in_f1 = open(file_path, \"r\")\n",
        "        in_f2 = open(file_path, \"r\")\n",
        "        list_of_removable_ngrams = [tuple_link[0] for tuple_link in sorted_list[0:i]]\n",
        "        line1 = in_f1.readline()\n",
        "        line2 = in_f2.readline()\n",
        "        total_bleu = 0\n",
        "        cnt = 0\n",
        "        while line1:\n",
        "            line1 = remove_ngrams_from_line(line1, list_of_removable_ngrams, ngram_size)\n",
        "            sentence_bleu_score = sentence_bleu([line2.split(\" \")], line1, \n",
        "                                                weights=(0.25,0.25,0.25,0.25), \n",
        "                                                smoothing_function=smoothing.method2)\n",
        "            total_bleu = total_bleu + sentence_bleu_score\n",
        "            line1 = in_f1.readline()\n",
        "            line2 = in_f2.readline()\n",
        "            cnt = cnt + 1\n",
        "\n",
        "        bleu_score = total_bleu / cnt\n",
        "        output_list.append(bleu_score)\n",
        "\n",
        "    pickle.dump(output_list, open(pickle_file_path, \"wb\"))\n",
        "\n",
        "    plt.title(\"BLEU-4 Dropoff Scores\")\n",
        "    plt.xlabel(\"Number of most common ngrams stripped\")\n",
        "    plt.ylabel(\"BLEU-4 score\")\n",
        "    plt.plot(indices, output_list, linewidth=2, color='r')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zPNpOvMxFXAe"
      },
      "source": [
        "Here, we have four changeable parameters:\n",
        "\n",
        "*   `num_iters`\n",
        "*   `n_gram`\n",
        "*   `file_path`\n",
        "*   `pickle_file_path`\n",
        "\n",
        "These details of these parameters covered above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UvpAl7YABHuD",
        "colab": {}
      },
      "source": [
        "# changeable parameters\n",
        "file_path = \"CodeNN_comments.txt\"\n",
        "ngram_size = 3\n",
        "pickle_file_path = \"codenn_trigram.p\" # must be a .p file\n",
        "num_iters = 100\n",
        "\n",
        "compute_and_plot(file_path, ngram_size, pickle_file_path, num_iters)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}