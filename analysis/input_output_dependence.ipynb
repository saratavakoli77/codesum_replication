{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dr1hzhNOIR8B"
   },
   "source": [
    "This notebook will help reproduce figure (4) in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iJaGgOyGIMZK",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "frS3_2GgKQBH"
   },
   "source": [
    "Here, we collect data by looking at a pair of files (an input (code) and output (comments) file). We take 2 random lines, and plot the bleu scores of the inputs (code lines) and outputs (comment lines)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qK-YerUwIv7E",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def collect_data(args):\n",
    "\tnum_samples = 10000 if args[\"num_samples\"] is None else int(args[\"num_samples\"])\n",
    "\tno_zeroes = args[\"no_zeroes\"]\n",
    "\n",
    "\toutput_csv_file = open(args[\"csv_file\"], \"w\")\n",
    "\toutput_csv_file.write(\"input_bleu,output_bleu\\n\")\n",
    "\n",
    "\tfile_inputs = open(args[\"input_file\"], \"r\")\n",
    "\tfile_outputs = open(args[\"output_file\"], \"r\")\n",
    "\n",
    "\tall_inputs = []\n",
    "\tall_outputs = []\n",
    "\n",
    "\tsmoothing = SmoothingFunction()\n",
    "\n",
    "\t\"\"\"\n",
    "\tHere, we take each pair of input-output lines, split them by space, and append them to lists\n",
    "\tall_inputs and all_outputs. For funcom, we make sure to remove the <s> and </s> tokens from the\n",
    "\toutputs (comments) to prevent artificially increasing BLEU scores.\n",
    "\t\"\"\"\n",
    "\tfor (input, output) in zip(file_inputs.readlines(), file_outputs.readlines()):\n",
    "\t\tinput_splitted, input_len = input.split(\" \"), len(input.split(\" \"))\n",
    "\t\toutput_splitted, output_len = output.split(\" \"), len(output.split(\" \"))\n",
    "\t\tall_inputs.append(input_splitted)\n",
    "\t\tall_outputs.append(output_splitted)\n",
    "\n",
    "\t\"\"\"\n",
    "\tHere, we iterate through the number of desired samples (10k in our setting). We randomly select\n",
    "\t2 input-output pairs without replacement to prevent (although unlikely) the possibility of\n",
    "\tpicking the exact same pairs. We calculate the BLEU using BLEU-4 with the appropriate smoothing\n",
    "\tfunction.\n",
    "\t\"\"\"\n",
    "\tfor iter in tqdm(range(num_samples)):\n",
    "\t\tidxes = np.random.choice(len(all_inputs), 2, replace=False)\n",
    "\n",
    "\t\tinput_bleu = sentence_bleu([all_inputs[idxes[0]]], all_inputs[idxes[1]], \n",
    "\t\t\t\t\t\t\t\t\tweights=(0.25,0.25,0.25,0.25), \n",
    "\t\t\t\t\t\t\t\t\tsmoothing_function=smoothing.method2)\n",
    "\t\toutput_bleu = sentence_bleu([all_outputs[idxes[0]]], all_outputs[idxes[1]], \n",
    "\t\t\t\t\t\t\t\t\tweights=(0.25,0.25,0.25,0.25), \n",
    "\t\t\t\t\t\t\t\t\tsmoothing_function=smoothing.method2)\n",
    "\t\tif no_zeroes:\n",
    "\t\t\t\"\"\"\n",
    "\t\t\tcontinue if we want to eliminate very small (essentially zero) values\n",
    "\t\t\t\"\"\"\n",
    "\t\t\tif input_bleu < 1e-5 or output_bleu < 1e-5:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\n",
    "\t\toutput_csv_file.write(f\"{input_bleu},{output_bleu}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rV2kU0vdI_73",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10000/10000 [00:07<00:00, 1317.15it/s]\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"input_file\": \"../../data/plot-data/bivariate/CodeNN/code.txt\",\n",
    "    \"output_file\": \"../../data/plot-data/bivariate/CodeNN/comments.txt\",\n",
    "    \"csv_file\": \"codenn.csv\",\n",
    "    \"num_samples\": 10000,\n",
    "    \"no_zeroes\": True\n",
    "}\n",
    "collect_data(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZBTgwZKqyLAd"
   },
   "source": [
    "Now that we've collected the data, we need to run the following commands in R (not done in this notebook), so fire up R studio and input these commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VhrB45Ogyk5G"
   },
   "source": [
    "**First install ggplot2 and hexbin for visualization.**\n",
    "\n",
    "install.packages(\"ggplot2\")\n",
    "library(\"ggplot2\")\n",
    "\n",
    "install.packages(\"hexbin\")\n",
    "library(\"hexbin\")\n",
    "\n",
    "**Read the BLEU data and plot.**\n",
    "\n",
    "data = read.csv(/Path/to/bivariate/data)\n",
    "\n",
    "d <- ggplot(data, aes(input_bleu, output_bleu))\n",
    "\n",
    "d + geom_hex(bins = 50) # number of bins can be varied for visualization purposes\n",
    "\n",
    "**If you want to plot multiple plots simulataneously (as seen in figure 4 in the paper)**:\n",
    "\n",
    "First go here: https://cran.r-project.org/web/packages/egg/vignettes/Ecosystem.html\n",
    "Copy the function grid_arrange_shared_legend into R Studio. The run the following additional commands:\n",
    "\n",
    "**Install some more packages**\n",
    "\n",
    "install.packages(\"gridExtra\")\n",
    "library(gridExtra)\n",
    "\n",
    "install.packages(\"ggplotGrob\")\n",
    "library(ggplotGrob)\n",
    "\n",
    "**Read .csv files for each dataset**\n",
    "\n",
    "data_1 = read.csv(/Path/to/bivariate/data_1)\n",
    "\n",
    "... (for all data files you want to plot)\n",
    "\n",
    "data_n = read.csv(/Path/to/bivariate/data_n)\n",
    "\n",
    "**Create the data holder**\n",
    "\n",
    "Some tips: You can change the ends of the limits and the bins for visualization purposes.\n",
    "\n",
    "d_1 = <- ggplot(data_1, aes(input_bleu, output_bleu)) + geom_hex(bins = 50) + ggtitle(title) + scale_x_continuous(limits=c(-1, 30)) + scale_y_continuous(limits=c(-1, 30))\n",
    "... (for all data files you want to plot)\n",
    "\n",
    "d_n = <- ggplot(data_n, aes(input_bleu, output_bleu)) + geom_hex(bins = 50) + ggtitle(title) + scale_x_continuous(limits=c(-1, 30)) + scale_y_continuous(limits=c(-1, 30))\n",
    "\n",
    "**Plot all data in a side-by-side plot**\n",
    "\n",
    "grid_arrange_shared_legend(d_1, ... ,d_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gOWyjX8LzyRh"
   },
   "source": [
    "To calculate the Spearman coefficients and the associated p-values, run this function with the correct path to the .csv file created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hc--oi_5z6mH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def calculate_spearman(path_to_csv: str) -> None:\n",
    "\tdf = pd.read_csv(path_to_csv)\n",
    "\tinput_bleu = df[\"input_bleu\"].tolist()\n",
    "\toutput_bleu = df[\"output_bleu\"].tolist()\n",
    "\tspearman = spearmanr(input_bleu, output_bleu)\n",
    "\tprint(spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ckG-nP6Z0CA0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.009602423650352758, pvalue=0.5064190177083514)\n"
     ]
    }
   ],
   "source": [
    "calculate_spearman('codenn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10000/10000 [00:12<00:00, 827.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.06030788571815664, pvalue=9.481267487435718e-08)\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"input_file\": \"../../data/plot-data/bivariate/DeepCom1/code.txt\",\n",
    "    \"output_file\": \"../../data/plot-data/bivariate/DeepCom1/comments.txt\",\n",
    "    \"csv_file\": \"DeepCom1.csv\",\n",
    "    \"num_samples\": 10000,\n",
    "    \"no_zeroes\": True\n",
    "}\n",
    "collect_data(args)\n",
    "calculate_spearman('DeepCom1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10000/10000 [00:48<00:00, 204.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.08390676557271166, pvalue=6.906940852597637e-14)\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"input_file\": \"../../data/plot-data/bivariate/DeepCom2/code.txt\",\n",
    "    \"output_file\": \"../../data/plot-data/bivariate/DeepCom2/comments.txt\",\n",
    "    \"csv_file\": \"DeepCom2.csv\",\n",
    "    \"num_samples\": 10000,\n",
    "    \"no_zeroes\": True\n",
    "}\n",
    "collect_data(args)\n",
    "calculate_spearman('DeepCom2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10000/10000 [00:11<00:00, 898.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.16859889278609977, pvalue=8.363130249969569e-56)\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"input_file\": \"../../data/plot-data/bivariate/Docstring1/code.txt\",\n",
    "    \"output_file\": \"../../data/plot-data/bivariate/Docstring1/comments.txt\",\n",
    "    \"csv_file\": \"Docstring1.csv\",\n",
    "    \"num_samples\": 10000,\n",
    "    \"no_zeroes\": True\n",
    "}\n",
    "collect_data(args)\n",
    "calculate_spearman('Docstring1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10000/10000 [00:11<00:00, 905.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.04913943609085451, pvalue=1.4126299564228146e-06)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"input_file\": \"../../data/plot-data/bivariate/Docstring2/code.txt\",\n",
    "    \"output_file\": \"../../data/plot-data/bivariate/Docstring2/comments.txt\",\n",
    "    \"csv_file\": \"Docstring2.csv\",\n",
    "    \"num_samples\": 10000,\n",
    "    \"no_zeroes\": True\n",
    "}\n",
    "collect_data(args)\n",
    "calculate_spearman('Docstring2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 10000/10000 [04:17<00:00, 38.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.0922174158360177, pvalue=7.001783577909612e-11)\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"input_file\": \"../../data/plot-data/bivariate/FunCom1/code.txt\",\n",
    "    \"output_file\": \"../../data/plot-data/bivariate/FunCom1/comments.txt\",\n",
    "    \"csv_file\": \"FunCom1.csv\",\n",
    "    \"num_samples\": 10000,\n",
    "    \"no_zeroes\": True\n",
    "}\n",
    "collect_data(args)\n",
    "calculate_spearman('FunCom1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 10000/10000 [04:22<00:00, 38.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.10639482515175742, pvalue=6.85939296807234e-14)\n"
     ]
    }
   ],
   "source": [
    "args = {\n",
    "    \"input_file\": \"../../data/plot-data/bivariate/FunCom2/code.txt\",\n",
    "    \"output_file\": \"../../data/plot-data/bivariate/FunCom2/comments.txt\",\n",
    "    \"csv_file\": \"FunCom2.csv\",\n",
    "    \"num_samples\": 10000,\n",
    "    \"no_zeroes\": True\n",
    "}\n",
    "collect_data(args)\n",
    "calculate_spearman('FunCom2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "bivariate_plots.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
